# -*- coding: utf-8 -*-
"""Module2_week2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a9mk8TGRBjWnZPKc8k4H31g5A1L3iSXb
"""

import pandas as pd

# Tạo DataFrame từ dữ liệu huấn luyện
data = {
    'Day': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10'],
    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Overcast', 'Sunny', 'Rain'],
    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal'],
    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak'],
    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes']
}

df = pd.DataFrame(data)

# Tính xác suất tiên nghiệm
p_yes = len(df[df['PlayTennis'] == 'Yes']) / len(df)
p_no = len(df[df['PlayTennis'] == 'No']) / len(df)

print(p_yes)
print(p_no)

#Câu 2 + 3
def conditional_probability(feature, value, target, target_value):
    return len(df[(df[feature] == value) & (df[target] == target_value)]) / len(df[df[target] == target_value])


outlook = 'Sunny'
temperature = 'Cool'
humidity = 'High'
wind = 'Strong'

p_outlook_given_yes = conditional_probability('Outlook', outlook, 'PlayTennis', 'Yes')
p_temperature_given_yes = conditional_probability('Temperature', temperature, 'PlayTennis', 'Yes')
p_humidity_given_yes = conditional_probability('Humidity', humidity, 'PlayTennis', 'Yes')
p_wind_given_yes = conditional_probability('Wind', wind, 'PlayTennis', 'Yes')

p_outlook_given_no = conditional_probability('Outlook', outlook, 'PlayTennis', 'No')
p_temperature_given_no = conditional_probability('Temperature', temperature, 'PlayTennis', 'No')
p_humidity_given_no = conditional_probability('Humidity', humidity, 'PlayTennis', 'No')
p_wind_given_no = conditional_probability('Wind', wind, 'PlayTennis', 'No')


p_x_given_yes = p_outlook_given_yes * p_temperature_given_yes * p_humidity_given_yes * p_wind_given_yes
p_x_given_no = p_outlook_given_no * p_temperature_given_no * p_humidity_given_no * p_wind_given_no

p_yes_given_x = p_x_given_yes * p_yes
p_no_given_x = p_x_given_no * p_no

print(p_yes_given_x)
print(p_no_given_x)

# Câu 4
total = p_yes_given_x + p_no_given_x
p_yes_given_x_normalized = p_yes_given_x / total
p_no_given_x_normalized = p_no_given_x / total

if p_yes_given_x_normalized > p_no_given_x_normalized:
    print("Kết luận: Chơi tennis")
else:
    print("Kết luận: Không chơi tennis")

import pandas as pd

# Khởi tạo dữ liệu
data = {
    "Day": ["Weekday", "Weekday", "Weekday", "Holiday", "Saturday", "Weekday", "Holiday", "Sunday", "Weekday", "Weekday",
            "Saturday", "Weekday", "Weekday", "Weekday", "Weekday", "Saturday", "Weekday", "Holiday", "Weekday", "Weekday"],
    "Season": ["Spring", "Winter", "Winter", "Winter", "Summer", "Autumn", "Summer", "Summer", "Winter", "Summer",
               "Spring", "Summer", "Winter", "Summer", "Winter", "Autumn", "Autumn", "Spring", "Spring", "Spring"],
    "Fog": ["None", "None", "None", "High", "Normal", "Normal", "High", "Normal", "High", "None",
            "High", "High", "Normal", "High", "Normal", "High", "None", "Normal", "Normal", "Normal"],
    "Rain": ["None", "Slight", "None", "Slight", "None", "None", "Slight", "None", "Heavy", "Slight",
             "Heavy", "Slight", "None", "None", "Heavy", "Slight", "Heavy", "Slight", "None", "Heavy"],
    "Class": ["On Time", "On Time", "On Time", "Late", "On Time", "Very Late", "On Time", "On Time", "Very Late", "On Time",
              "Cancelled", "On Time", "Late", "On Time", "Very Late", "On Time", "On Time", "On Time", "On Time", "On Time"]
}

df = pd.DataFrame(data)

class_counts = df['Class'].value_counts()
total_count = len(df)

# Câu hỏi 5: Xác suất xảy ra của các sự kiện "Class"
P_On_Time = class_counts['On Time'] / total_count
P_Late = class_counts['Late'] / total_count
P_Very_Late = class_counts['Very Late'] / total_count
P_Cancelled = class_counts['Cancelled'] / total_count

print(f"P('Class' = 'On Time') = {P_On_Time:.4f}")
print(f"P('Class' = 'Late') = {P_Late:.4f}")
print(f"P('Class' = 'Very Late') = {P_Very_Late:.4f}")
print(f"P('Class' = 'Cancelled') = {P_Cancelled:.4f}")

# Sự kiện thử nghiệm
X = {"Day": "Weekday", "Season": "Winter", "Fog": "High", "Rain": "Heavy"}

# Tính xác suất có điều kiện
def conditional_prob(attribute, value, given_class):
    subset = df[df['Class'] == given_class]
    count_attribute = subset[attribute].value_counts().get(value, 0)
    return count_attribute / len(subset)

# Tính P(X|Class)
def calculate_P_X_given_Class(X, class_value):
    P = 1
    for attribute, value in X.items():
        P *= conditional_prob(attribute, value, class_value)
    return P

P_X_given_On_Time = calculate_P_X_given_Class(X, 'On Time')
P_X_given_Late = calculate_P_X_given_Class(X, 'Late')
P_X_given_Very_Late = calculate_P_X_given_Class(X, 'Very Late')
P_X_given_Cancelled = calculate_P_X_given_Class(X, 'Cancelled')

# Tính P(X và Class)
P_X_and_On_Time = P_X_given_On_Time * P_On_Time
P_X_and_Late = P_X_given_Late * P_Late
P_X_and_Very_Late = P_X_given_Very_Late * P_Very_Late
P_X_and_Cancelled = P_X_given_Cancelled * P_Cancelled

# Chuẩn hóa
P_X = P_X_and_On_Time + P_X_and_Late + P_X_and_Very_Late + P_X_and_Cancelled

P_Class_given_X_On_Time = P_X_and_On_Time / P_X
P_Class_given_X_Late = P_X_and_Late / P_X
P_Class_given_X_Very_Late = P_X_and_Very_Late / P_X
P_Class_given_X_Cancelled = P_X_and_Cancelled / P_X

print(f"P('Class' = 'On Time' | X) ∝ {P_Class_given_X_On_Time:.4f}")
print(f"P('Class' = 'Late' | X) ∝ {P_Class_given_X_Late:.4f}")
print(f"P('Class' = 'Very Late' | X) ∝ {P_Class_given_X_Very_Late:.4f}")
print(f"P('Class' = 'Cancelled' | X) ∝ {P_Class_given_X_Cancelled:.4f}")

def create_train_data():

  data=[['Sunny','Hot', 'High', 'Weak', 'no'],
        ['Sunny','Hot', 'High', 'Strong', 'no'],
        ['Overcast','Hot', 'High', 'Weak', 'yes'],
        ['Rain','Mild', 'High', 'Weak', 'yes'],
        ['Rain','Cool', 'Normal', 'Weak', 'yes'],
        ['Rain','Cool', 'Normal', 'Strong', 'no'],
        ['Overcast','Cool', 'Normal', 'Strong', 'yes'],
        ['Overcast','Mild', 'High', 'Weak', 'no'],
        ['Sunny','Cool', 'Normal', 'Weak', 'yes'],
        ['Rain','Mild', 'Normal', 'Weak', 'yes']
        ]
  return np.array(data)
train_data = create_train_data()
print(train_data)

def compute_prior_probablity(train_data):
  y_unique = ['no', 'yes']
  prior_probability = np.zeros(len(y_unique))
  for i in range(0,len(y_unique)):
    prior_probability[i]=len(np.where(train_data[:,4] == y_unique[i])[0])/len(train_data)
  return prior_probability

prior_probablity = compute_prior_probablity(train_data)
print("P(“Play Tennis” = No)", prior_probablity[0])
print("P(“Play Tennis” = Yes)", prior_probablity[1])

def compute_conditional_probability(train_data):
  y_unique = ['no', 'yes']
  conditional_probability = []
  list_x_name = []
  for i in range(0,train_data.shape[1]-1):
    x_unique = np.unique(train_data[:,i])
    print("x_unique", x_unique)

    list_x_name.append(x_unique)

    x_conditional_probability = np.zeros((len(y_unique),len(x_unique)))
    for j in range(0,len(y_unique)):
      for k in range(0,len(x_unique)):
        x_conditional_probability[j,k]= len(np.where((train_data[:,i] == x_unique[k]) & (train_data[:,4] == y_unique[j]))[0])/len(np.where(train_data[:,4] == y_unique[j])[0])

    conditional_probability.append(x_conditional_probability)
  return conditional_probability, list_x_name

train_data = create_train_data()
_, list_x_name  = compute_conditional_probability(train_data)
print("x1 = ",list_x_name[0])
print("x2 = ",list_x_name[1])
print("x3 = ",list_x_name[2])
print("x4 = ",list_x_name[3])

def train_naive_bayes(train_data):
    # Step 1: Calculate Prior Probability
    prior_probability = compute_prior_probablity(train_data)

    # Step 2: Calculate Conditional Probability
    conditional_probability, list_x_name  = compute_conditional_probability(train_data)

    return prior_probability,conditional_probability, list_x_name

data = create_train_data()
prior_probability,conditional_probability, list_x_name = train_naive_bayes(data)

#This function is used to return the index of the feature name
def get_index_from_value(feature_name, list_features):
  return np.where(list_features == feature_name)[0][0]

#Question: 4.4.1
train_data = create_train_data()
_, list_x_name  = compute_conditional_probability(train_data)
outlook = list_x_name[0]
i1 = get_index_from_value("Overcast", outlook)
i2 = get_index_from_value("Rain", outlook)
i3 = get_index_from_value("Sunny", outlook)

print(i1, i2, i3)

train_data = create_train_data()
conditional_probability, list_x_name  = compute_conditional_probability(train_data)
# Compute P("Outlook"="Sunny"|Play Tennis"="Yes")
x1=get_index_from_value("Sunny",list_x_name[0])
print("P('Outlook'='Sunny'|Play Tennis'='Yes') = ", np.round(conditional_probability[0][1, x1],2))

#Question: 4.4.3
train_data = create_train_data()
conditional_probability, list_x_name  = compute_conditional_probability(train_data)
# Compute P("Outlook"="Sunny"|Play Tennis"="No")
x1=get_index_from_value("Sunny",list_x_name[0])
print("P('Outlook'='Sunny'|Play Tennis'='No') = ", np.round(conditional_probability[0][0, x1],2))

####################
# Prediction
####################
def prediction_play_tennis(X, list_x_name, prior_probability, conditional_probability):

    x1=get_index_from_value(X[0],list_x_name[0])
    x2=get_index_from_value(X[1],list_x_name[1])
    x3=get_index_from_value(X[2],list_x_name[2])
    x4=get_index_from_value(X[3],list_x_name[3])

    p0=prior_probability[0] \
    *conditional_probability[0][0,x1] \
    *conditional_probability[1][0,x2] \
    *conditional_probability[2][0,x3] \
    *conditional_probability[3][0,x4]

    p1=prior_probability[1]\
    *conditional_probability[0][1,x1]\
    *conditional_probability[1][1,x2]\
    *conditional_probability[2][1,x3]\
    *conditional_probability[3][1,x4]

    # print(p0, p1)

    if p0>p1:
        y_pred=0
    else:
        y_pred=1

    return y_pred

# prediction_play_tennis()

#4.6.1
X = ['Sunny','Cool', 'High', 'Strong']
data = create_train_data()
prior_probability,conditional_probability, list_x_name = train_naive_bayes(data)
pred =  prediction_play_tennis(X, list_x_name, prior_probability, conditional_probability)

if(pred):
  print("Ad should go!")
else:
  print("Ad should not go!")

from sklearn import datasets
import numpy as np

def create_train_data_iris():
  data = np.loadtxt("iris.data.txt", delimiter=",", dtype=str)
  return data

def compute_prior_probablity_iris(train_data):
  y_unique = np.unique(train_data[:,4])
  prior_probability = np.zeros(len(y_unique))
  for i in range(0,len(y_unique)):
    prior_probability[i]=len(np.where(train_data[:,4] == y_unique[i])[0])/len(train_data)
  return prior_probability

def compute_conditional_probability_iris(train_data):
  y_unique = np.unique(train_data[:,4]) # 0 for Setosa, 1 for Versicolour, 2 for Virginica
  x_feature = 4
  conditional_probability = []
  list_x_name = []
  for i in range(0,train_data.shape[1]-1):
    x_conditional_probability = np.zeros((len(y_unique), 2))
    for j in range(0,len(y_unique)):
        mean = np.mean((train_data[:,i][np.where(train_data[:,4] == y_unique[j])]).astype(float))
        sigma =  np.std((train_data[:,i][np.where(train_data[:,4] == y_unique[j])]).astype(float))
        sigma = sigma * sigma
        x_conditional_probability[j]= [mean, sigma]

    conditional_probability.append(x_conditional_probability)
  return conditional_probability

import math
#Define the Gaussian function
def gauss(x, mean, sigma):
  result = (1.0 / (np.sqrt(2*math.pi*sigma))) \
  * (np.exp(-(float(x) - mean) ** 2 / (2 * sigma)))
  return result

###########################
# Train Naive Bayes Model
###########################
def train_gaussian_naive_bayes(train_data):
    # Step 1: Calculate Prior Probability
    prior_probability = compute_prior_probablity_iris(train_data)

    # Step 2: Calculate Conditional Probability
    conditional_probability  = compute_conditional_probability_iris(train_data)

    return prior_probability,conditional_probability

# data = create_train_data_iris()
# conditional_probability = train_gaussian_naive_bayes(data)

def prediction_iris(X,  prior_probability, conditional_probability):

    p0=prior_probability[0] \
    *gauss(X[0], conditional_probability[0][0][0],conditional_probability[0][0][1])  \
    *gauss(X[1], conditional_probability[1][0][0],conditional_probability[1][0][1])  \
    *gauss(X[2], conditional_probability[2][0][0],conditional_probability[2][0][1])  \
    *gauss(X[3], conditional_probability[3][0][0],conditional_probability[3][0][1])

    p1=prior_probability[1] \
    *gauss(X[0], conditional_probability[0][1][0],conditional_probability[0][1][1])  \
    *gauss(X[1], conditional_probability[1][1][0],conditional_probability[1][1][1])  \
    *gauss(X[2], conditional_probability[2][1][0],conditional_probability[2][1][1])  \
    *gauss(X[3], conditional_probability[3][1][0],conditional_probability[3][1][1])

    p2=prior_probability[2] \
    *gauss(X[0], conditional_probability[0][2][0],conditional_probability[0][2][1])  \
    *gauss(X[1], conditional_probability[1][2][0],conditional_probability[1][2][1])  \
    *gauss(X[2], conditional_probability[2][2][0],conditional_probability[2][2][1])  \
    *gauss(X[3], conditional_probability[3][2][0],conditional_probability[3][2][1])

    # print(p0, p1)

    list_p = [p0, p1, p2]

    return list_p.index(np.max(list_p))

# prediction_play_tennis()